---
alwaysApply: true
---

# Code Efficiency Patterns (Big O Awareness)

## Data Structure Selection

### O(1) vs O(n) Lookups
```python
# ❌ O(n) - scanning list for membership
if item in my_list:  # Scans entire list
    ...

# ✅ O(1) - hash lookup
if item in my_set:  # Constant time
    ...

# ✅ Convert once if checking multiple times
allowed = set(allowed_list)  # O(n) once
for x in items:
    if x in allowed:  # O(1) each time
        ...
```

### dict over repeated list searches
```python
# ❌ O(n²) - nested loop searching
for user in users:
    for order in orders:
        if order.user_id == user.id:  # O(n) each time
            ...

# ✅ O(n) - index once, lookup O(1)
orders_by_user = {}
for order in orders:
    orders_by_user.setdefault(order.user_id, []).append(order)

for user in users:
    user_orders = orders_by_user.get(user.id, [])  # O(1)
```

## Avoid Hidden O(n) Operations

```python
# ❌ O(n) - list.index() scans
idx = my_list.index(item)

# ❌ O(n) - list.remove() scans then shifts
my_list.remove(item)

# ❌ O(n) - list.insert(0, x) shifts all elements
my_list.insert(0, new_item)

# ✅ Use deque for O(1) front operations
from collections import deque
d = deque()
d.appendleft(item)  # O(1)
```

## Comprehensions Over Loops

```python
# ❌ Slower, more verbose
result = []
for x in items:
    if x.valid:
        result.append(x.value)

# ✅ Faster (C-level loop), clearer intent
result = [x.value for x in items if x.valid]
```

## Generator Expressions for Large Data

```python
# ❌ Creates entire list in memory
sum([x * x for x in range(1_000_000)])

# ✅ Generator - O(1) memory
sum(x * x for x in range(1_000_000))

# ✅ any()/all() short-circuit with generators
if any(is_valid(x) for x in huge_list):  # Stops at first True
    ...
```

## String Building

```python
# ❌ O(n²) - string concatenation in loop
result = ""
for s in strings:
    result += s  # Creates new string each time

# ✅ O(n) - join is optimized
result = "".join(strings)
```

## dict.get() vs try/except vs `in` check

```python
# ❌ Two lookups
if key in d:
    value = d[key]

# ❌ Exception overhead (fine if key usually exists)
try:
    value = d[key]
except KeyError:
    value = default

# ✅ Single lookup
value = d.get(key, default)
```

## Caching Expensive Computations

```python
# For pure functions (same input → same output)
from functools import cache

@cache  # ⚠️ Not thread-safe in 3.14t without care
def expensive(n: int) -> int:
    ...

# ✅ Thread-safe caching pattern (from python-compliance.mdc)
class Cache:
    def __init__(self) -> None:
        self._data: dict[str, Any] = {}
        self._lock = threading.Lock()
    
    def get_or_compute(self, key: str, compute: Callable[[], Any]) -> Any:
        if key in self._data:
            return self._data[key]
        with self._lock:
            if key in self._data:
                return self._data[key]
            self._data[key] = compute()
            return self._data[key]
```

## Dead Code Indicators

Watch for:
- Functions never called (grep for usages)
- Imports not used (ruff F401 catches this)
- Variables assigned but never read (ruff F841)
- Unreachable code after return/raise (ruff catches this)
- Parameters that are always the same value
- Feature flags that are always True/False

## Bloat Indicators

Watch for:
- Classes with only `__init__` and one method → use a function
- Inheritance depth > 2 → prefer composition
- Functions > 50 lines → break up
- Files > 500 lines → split module
- More than 5 parameters → use a dataclass/config object
- Wrapper classes that just delegate → remove the wrapper